<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<title>ARNL: Main Page</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript">
  $(document).ready(initResizable);
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td style="padding-left: 0.5em;">
   <div id="projectname">ARNL
   &#160;<span id="projectnumber">1.9.3</span>
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.1 -->
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li class="current"><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="annotated.html"><span>Classes</span></a></li>
      <li><a href="examples.html"><span>Examples</span></a></li>
    </ul>
  </div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(document).ready(function(){initNavTree('index.html','');});
</script>
<div id="doc-content">
<div class="header">
  <div class="headertitle">
<div class="title">ARNL Documentation</div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p>Copyright (c) 2004, 2005 ActivMedia Robotics, LLC<br/>
 Copyright (c) 2006-2010 MobileRobots Inc.<br/>
 Copyright (c) 2011-2015 Adept Technology<br/>
 All rights reserved. </p>
<h1><a class="anchor" id="arnlintro"></a>
Introduction to ARNL Laser Localization</h1>
<p>ARNL is MobileRobots Inc.'s software development kit for localization with a scanning laser sensor in an indoor building environment.</p>
<p>ARNL's localization task (<a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a>) uses the robot odometry, laser sensor data and a prepared environment map to find the most probable position of the robot within that map. Once initialized, the robot's pose in the map coordinate system is constantly updated by this task.</p>
<p>Robot path planning and navigation is provided by the BaseArnl library. BaseArnl also provides some base classes and utilities used by ARNL, as well as ARIA and ArNetworking libraries used by ARNL.</p>
<p><a href="../BaseArnl-Reference/index.html" target="_top">See the BaseArnl documentation for path planning and navigation information. </a></p>
<p>There are other libraries which implement different localization techniques, Which localization libraries you have will depend on what software options were purchased. <a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> which uses data obtained from a scanning laser range finder (ArSick) to localize. The 'SonArnl' localization library contains ArSonarLocalizationTask which uses the sonar (ultrasonic range sensors) for more approximate localization. SonArnl is included with any MobileRobots robot platform and can be used with any MobileRobots robot equipped with sonar. The 'Mogs' localization library contains ArGPSLocalizationTask which uses data from a GPS receiver to localize the robot in a georegistered map. GPS localization is part of the "MOGS Outdoor Navigation" accessory package.</p>
<p>It is possible to use more than one localization tequnique simultaneosly, merging them into a unified result, though this feature is still experimental. All of the localization task classes from the various libraries are derived from <a class="elRef" doxygen="BaseArnl.tag:../BaseArnl-Reference//" href="../BaseArnl-Reference/classArBaseLocalizationTask.html">ArBaseLocalizationTask</a> in the BaseArnl library.</p>
<p>ARNL currently requires a SICK LMS laser sensor or very similar laser device.</p>
<p>This reference manual describes using laser localization with the Arnl library. The <a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> class works asynchronously to localize a robot in a known (mapped) indoor environment using data from a laser rangefinder and the robot's odometry. Besides a prepared map created and edited with Mapper3 (tm) or similar utility, <a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> requires the use of a MobileRobots or ActivMedia robot platform or simulator equipped with a laser range-finding sensor.</p>
<p>The map (ArMap, in the Aria library) used in localization and planning contains several types of data and objects. Maps may include designated forbidden areas, goals and a "home" poses.</p>
<h1><a class="anchor" id="arnlproguse"></a>
Programming and Using ArLocalizationTask</h1>
<p><a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> implements the Monte Carlo Localization Algorithm to accurately place the robot within a given map of its operating environment, as derived from laser-ranging and robot odometry information. The localization task is meant to be initialized and run as a separate thread.</p>
<p>To write a program using ARNL, include the Arnl/Aria.h, Arnl/Arnl.h, Arnl/ArLocalizationTask.h, and, if needed, Arnl/ArNetworking.h header files with your source code and link it with libBaseArnl, libAriaForArnl, libAriaNetworkingForArnl, and libArnl libraries in Arnl/lib.</p>
<p>You need to include five basic objects to enable localization: ArRobot, ArMap, one or more ArLaser objects, <a class="elRef" doxygen="BaseArnl.tag:../BaseArnl-Reference//" href="../BaseArnl-Reference/classArPathPlanningTask.html">ArPathPlanningTask</a>, and <a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a>. Other objects will also be required, such as ArRobotConnector, ArLaserConnector, etc.</p>
<p>For a complete example program using ARNL see <a class="el" href="arnlServer_8cpp-example.html">arnlServer.cpp</a></p>
<p>First create an <a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> object with an instantiated ArRobot, an ArLaser object and a map of the robot's environment, explicitly as a file or from ArMap. For example,</p>
<div class="fragment"><div class="line"><span class="comment">// Create the localization task (it will start its own thread here)</span></div>
<div class="line"><a class="code" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> myLocTask(myRobot, myLaser, mapname);</div>
</div><!-- fragment --><p>Next initialize the robot's location inside the map and do an initial localization. This initial localization may take several seconds.</p>
<p>Before running your ARNL-enabled application, you can first physically position the robot (or simulated robot) at a starting position, such as its home point or at the place corresponding to (0,0,0) in the map. ARNL can sucessfully perform the initial localization at that known point when <code>localizeRobotAtHomeBlocking()</code> is called.</p>
<div class="fragment"><div class="line"><span class="comment">// Set the initial pose to the robot&#39;s &quot;Home&quot; position from the map, or</span></div>
<div class="line"><span class="comment">// (0,0,0) if none, then let the localization thread take over.</span></div>
<div class="line">myLocTask.localizeRobotAtHomeBlocking();</div>
</div><!-- fragment --><p>If it is not possible to move the robot to a home position, you can connect to the program (arnlServer) with MobileEyes and use its "Localize Robot to 
Point" command to position the robot in the map at its current pose in the map.</p>
<p>Thereafter, <a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> thread automatically acts to relocate the robot in the map. To conserve processing resources, automatic localization updates happen only when the robot has moved beyond set translational and/or rotational limits. By default, these limits are set to +-200 mm translation and +-5 degrees rotation but may be changed by modifying ARNL's configuration parameters.</p>
<p>You can also use tArBaseLocalizationTask::setRobotPose(), <a class="el" href="classArLocalizationTask.html#afe38e3fc30d46cc2ab2c348366ccdf6b" title="Try to localize at each home point at the map, and set the robot pose to the point with best score...">ArLocalizationTask::localizeRobotAtHomeBlocking()</a>, or <a class="el" href="classArLocalizationTask.html#a35969f66db214d2fa1f606dbde01a407" title="Request that the task later localize the robot at a map home \ position, but then return immediately...">ArLocalizationTask::localizeRobotAtHomeNonBlocking()</a>, to relocalize the robot at a new position at any time.</p>
<div class="fragment"><div class="line"><span class="comment">// If we know that the robot is actually at or near &#39;pose&#39; in the map, we can</span></div>
<div class="line"><span class="comment">// relocalize there:</span></div>
<div class="line">myLocTask.setRobotPose(pose);</div>
</div><!-- fragment --><h1><a class="anchor" id="arnlconfig"></a>
Configuring ARNL Parameters</h1>
<p>Aria and Arnl may be configured by modifying params/arnl.p, or through MobileEyes once it's running (if the program includes ArServerHandlerConfig object), or in the program through the global ArConfig object in Aria. For example, you can change the name of the map file used, change the localization trigger distance thresholds, etc. Each parameter has a description. The parameters are also described below. For most applications, only the "Normal" level parameters usually need to be changed, and sometimes a few "Advanced".</p>
<p>For explanation of the parameters, see <a class="el" href="index.html#arnlparameters">ARNL Laser Localization Parameters in Detail</a> below.</p>
<h1><a class="anchor" id="arnlresultstates"></a>
Laser Localization Results and States</h1>
<p>Each time <a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> acts to update the robot's position in the map, it resets the pose of the ArRobot in ARIA (unless set not to do so). Hence, you may directly read the pose from the ArRobot object. In addition there are a number of functions in the <a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> class which can return the current robot location and the states of the localization. These flags and scores show the state of the localization. These functions include getLocalizationScore(), getSensorBelief(), getState(), getIdleFlag().</p>
<p>Since the localization task deals with a map and builds its own occupancy grid, the class also provides access to the map and grid using member functions. Get these data by including the related include files and member functions.</p>
<h1><a class="anchor" id="arnlfailcallback"></a>
Getting Lost and the Failed Callback.</h1>
<p>One of the important considerations with any localization system is to know when it is lost. With the laser localization, we have one primary measure called PassThreshold which is the ratio of the laser readings that match with the map points to the total number of laser points. If this score falls below the PassThreshold, the Monte Carlo localization will stop trying to correct the robot pose from its sensor update step. Once this threshold is crossed under, the certainity of the robot pose will progressively get worse as the robot moves. This measure of uncertainity will be directly related to the amount of motion described by the robot kinematics and error parameters such as KmmPermm etc. This measure of uncertainity will be tracked in the Kalman filter during every cycle as a distance in the XY space. When this spread grows beyond a LostThresholdDistance the robot is considered completely lost. The localization thread will call the fail callbacks as soon as this happens.</p>
<p>Note that the PassThreshold and the LostThresholdDistance are related. They come into play in sequence. If the PassThreshold is too low, say 0.1, it is unlikely that the robot will ever report itself lost using MCL. So a low PassThreshold like 0.2 and a LostThresholdDistance of 100mm is useful only for situations where the environment is fairly unchanged from the map used. In situations such as in a warehouse where a significant area of the map during its travel can be different from the map, it is better to use a higher PassThreshold such as 0.5 and a LostThresholdDistance of about 1000mm.</p>
<p><a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> can alert your program if it fails to update localization while running. In order to do this, add a callback function to the class using <a class="el" href="classArLocalizationTask.html#a7a979b768479d09cba163b5eaa6dd7c0" title="Adds a callback which will be called when localization fails.">ArLocalizationTask::addFailedLocalizationCB()</a>. Remove the callback using the <a class="el" href="classArLocalizationTask.html#a5b8d952240e1a9937579a61e675c1701" title="Removes a localization callback.">ArLocalizationTask::remFailedLocalizationCB()</a> when finished. The integer argument is a count of how many localization attempts have failed so far.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;Aria/Aria.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;Arnl.h&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;ArLocalizationTask.h&quot;</span></div>
<div class="line"></div>
<div class="line"><span class="keyword">class </span>MyClass {</div>
<div class="line">  <a class="code" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> *myLocTask;</div>
<div class="line">  ArFunctor1C&lt;MyClass, int&gt; myLocFailedCB;</div>
<div class="line">  <span class="keywordtype">void</span> failed(<span class="keywordtype">int</span> n);</div>
<div class="line"><span class="keyword">public</span>:</div>
<div class="line">  MyClass(<a class="code" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> *locTask);</div>
<div class="line">  ~MyClass();</div>
<div class="line">};</div>
<div class="line"></div>
<div class="line">MyClass::MyClass(<a class="code" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> *locTask) :</div>
<div class="line">  myLocTask(locTask),</div>
<div class="line">  myLocFailedCB(this, &amp;MyClass::failed)</div>
<div class="line">{</div>
<div class="line">  locTask-&gt;<a class="code" href="classArLocalizationTask.html#a7a979b768479d09cba163b5eaa6dd7c0" title="Adds a callback which will be called when localization fails.">addFailedLocalizationCB</a>(&amp;myLocFailedCB);</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line">MyClass::~MyClass()</div>
<div class="line">{</div>
<div class="line">  locTask-&gt;<a class="code" href="classArLocalizationTask.html#a5b8d952240e1a9937579a61e675c1701" title="Removes a localization callback.">remFailedLocalizationCB</a>(&amp;myLocFailedCB);</div>
<div class="line">}</div>
<div class="line"></div>
<div class="line"><span class="keywordtype">void</span> MyClass::failed(<span class="keywordtype">int</span> n)</div>
<div class="line">{</div>
<div class="line">  ArLog::log(ArLog::Normal, <span class="stringliteral">&quot;Localization failure.&quot;</span>);</div>
<div class="line">}</div>
</div><!-- fragment --><h1><a class="anchor" id="arnlmapping"></a>
Making Maps for Laser Localization</h1>
<p>To localize and navigate, ARNL needs a map of the robot's operating environment showing obstacles to plan around (it will also plan around any unmapped but visible obstacles using sensors such as the laser or sonar). Maps may also contain logical features such as goal points, forbidden areas, and more.</p>
<p>The mapping process is different for each localization method, though the map files are compatible and can be reused if they contain enough information useful to other methods (for example, laser localization in particular needs an accurate map of laser-sensed obstacles to match with laser readings).</p>
<p>To learn more about creating a map for laser localization with Arnl, see <a href="../Mapping.txt">Mapping.txt</a>.</p>
<h1><a class="anchor" id="arnladvanced"></a>
Some Advanced Features of ARNL Laser Localization</h1>
<p>In addition to the basic laser localization, ARNL has advanced features which enable the robot to localize in a more specialized manner. Some of these are as follows. These features are complex to use. If you think you need any of them and have any questions, please ask on the aria-users forum.</p>
<ol>
<li>
<p class="startli"></p>
<p>Reflectors: The SICK laser range finder can not only sense the range of an object but also compute its reflectivity. If the robot environment is marked with special reflective tape (manufactured by SICK), the SICK can detect it. ARNL can use the known position of the landmarks on the map and the reflectors it sees in its current laser view to compute the pose of the robot. To achieve this, ARNL uses an extended Kalman filter to fuse the movement from the wheel encoders and the reflections from the laser. The resulting pose computed from the reflectors can be fused with the pose from the MCL localization. If enabled, ARNL can also compute the pose using a closed form solution of the landmark equations. This triangulation computation can compute a solution whenever more than one reflectors come into view. This advanced feature was added to ARNL to enable the robot to localize even in locations such as a factory where the environment varies so widely that the robot loses localization using the regular MCL localization. To use reflectors, the map used must contain the reflector data, and the user must enable the reflector bits for the SICK laser by including the following command line arguments: <code>-laserReflectorBits 3ref -laserUnits 1cm'</code> (For example, <code>guiServer -map reflectors.map -laserReflectorBits 3ref -laserUnits 1cm</code>). </p>
<p></p>
<p></p>
<p>To get the reflector localization to work, you will need to use a map created with the Mapper3 software from MobileRobots. Please refer to the Mapper documentation to create a map and set it to display the reflectors on MobileEyes. </p>
<p></p>
<p class="endli"></p>
</li>
<li>
<p class="startli">Inter-robot communication and mutual avoidance (ARNL laser localization package only): The multi-robot networking services allow robots to communicate their positions and path data either in a peer-to-peer fashion, or through a central server, to better avoid each other in a multiple-robot application. To use this feature, you must create an <a class="elRef" doxygen="BaseArnl.tag:../BaseArnl-Reference//" href="../BaseArnl-Reference/classArServerHandlerMultiRobotPeer.html">ArServerHandlerMultiRobotPeer</a> or an <a class="elRef" doxygen="BaseArnl.tag:../BaseArnl-Reference//" href="../BaseArnl-Reference/classArServerHandlerMultiRobot.html">ArServerHandlerMultiRobot</a> object, an <a class="elRef" doxygen="BaseArnl.tag:../BaseArnl-Reference//" href="../BaseArnl-Reference/classArMultiRobotPeerRangeDevice.html">ArMultiRobotPeerRangeDevice</a> or an <a class="elRef" doxygen="BaseArnl.tag:../BaseArnl-Reference//" href="../BaseArnl-Reference/classArMultiRobotRangeDevice.html">ArMultiRobotRangeDevice</a>, configure relevant parameters, and use an ArClientSwitchManager to manage communication with a central server if using a central server. See class documentation, centralServerExample.cpp, and arnlServer.cpp for details. </p>
<p class="endli"></p>
</li>
<li>
<p class="startli"></p>
<p>Use of other robots for localization: When multiple robots are sharing the same map, either through a central management server, or via peer-to-peer communication, there can be situations where the robot senses other robots nearby rather surronding environment. In such cases the known poses and radii of the other robots (obtained from the central server) can be used for aiding instead of losing localization. ARNL now has the capability of adding known but unmapped objects in the map and using them for localization. Enable this by calling <a class="el" href="classArLocalizationTask.html#a78e68e0811350c2bc1d4c0626b33e5af" title="Sets the callback function for localization to know about other robots.">ArLocalizationTask::setMultiRobotCallback()</a>. A callback to provide to setMultiRobotCallback() can be obtained by calling getOtherRobotsCB() on either a <a class="elRef" doxygen="BaseArnl.tag:../BaseArnl-Reference//" href="../BaseArnl-Reference/classArMultiRobotPeerRangeDevice.html">ArMultiRobotPeerRangeDevice</a> object (for peer-to-peer communication), or a ArMultiRobotCentralRangeDevice object (for communication via a central server). </p>
<p></p>
<p class="endli"></p>
</li>
<li>
<p class="startli"></p>
<p>Ray Tracing for Initial localization: The truth of the initial localization of the robot before it starts to move is essential to keep the robot localized when it does move. Since the samples during initialization are spread about the assumed position of the robot, some samples will score high even though the sensor rays in such a pose have to trace through occupied cells to land on another occupied cell. To avoid this, we use a computationally intensive ray tracing to avoid high scores for such sensor impossiblities. This ray tracing is not done for localization triggered after a move because of the computation load. Note that this new feature will cause the initial localization to take longer than was the case earlier. During this initialization the robot localization state will be set to "lost" and the user may not be able to move the robot until this localization finishes successfully. </p>
<p></p>
<p class="endli"></p>
</li>
<li>
<p class="startli"></p>
<p>Localization Manager. ARNL now has the capablility of localizing the robot in a map using multiple methods such as MCL, Reflector based localization, GPS based outdoor localization (and and perhaps others in the future). When several localizations provide their estimates of the robot pose with varying degrees of accuracy, ARNL uses the localization manager to compute a weighted average of their estimates to find an optimal pose. The weights in the averaging is based on the variance matrices of their respective estimates. The localization manager does the actual move of the robots pose to this optimal pose using the moveTo command. (Earlier, the lone <a class="el" href="classArLocalizationTask.html" title="Task that performs continuous localization of the robot with a laser range sensor in a seperate async...">ArLocalizationTask</a> handled this moveTo). </p>
<p></p>
<p></p>
<p>To use the localization manager, you must construct the separate localization tasks and add them to the localization manager one by one. The act of adding a localization task to the manager suppresses its ability to directly alter the robot pose using moveTo and instead lets the manager do it for them. </p>
<p></p>
<p class="endli"></p>
</li>
</ol>
<h1><a class="anchor" id="arnlparameters"></a>
ARNL Laser Localization Parameters in Detail</h1>
<p>You can tune many parameters in ARNL to customize the behavior of the robot according to the robot's environment. These parameters are obtained by loading a parameter file using ArConfig. By default, ARNL will load parameters from <code>arnl.p</code> and SONARNL will load parameters from <code>sonarnl.p</code>. Parameters may also be changed on-line through MobileEyes.</p>
<p>For example, if the environment has few unmapped obstacles and is relatively fixed, the user can get away with a high value of PassThreshold for the localization threshold.</p>
<p>Changing some of these parameters can result in unintended consequences due to the limited resources such as the speed of the on board computer and memory. For example increasing the no of samples by orders of magnitude like to say 10000 may increase computation load to such an extent that all threads may lose sync and cause the system to fail.</p>
<p>(Remember, always test your software carefully in a controlled environment.)</p>
<p>The following subsection will list MCL laser localization related parameters and their use in arnl.p. The default values are noted in paratheses.</p>
<p>Key MCL Localization parameters:</p>
<ol>
<li>
Map: The path to the map filename of the environment the robot will localized in and navigating in. </li>
<li>
NumSamples: (2000) No of pose samples for MCL. The larger this number, the more computation will localization take. Too low a number will cause the robot to lose localization. </li>
<li>
NumSamplesAtInit: (4000) No of pose samples for MCL when initializing the robot in the map. Since this is presumably done when the robot is at rest, it can be larger than NumSamples and use more computation for more accuracy. (A value of 0 will make it equal to NumSamples). </li>
<li>
AdjustNumSamplesFlag: (false) The number of samples is by default kept high to keep the robot from losing localization even after initialization. This number can be lowered during motion in places of the map where the localization score is high to reduce the computation load. Set this flag to true if you want to vary the number of samples with the localization score. (As the score drops, the no of samples will rise)"). </li>
<li>
GridRes: (100 mm) The resolution of the occupancy grid representing the map in mm. Smaller resolution results in more accuracy but more computation. </li>
<li>
PassThreshold (0.2) After MCL sensor correction, the sample with the maximum probability will have a score based on the match between sensor and the map points. This is the minimum score out of 1.0 to be considered localized. Note that this threshold now is not the only measure of the robot being lost. Once the score drops below PassThreshold, the robot has to move a significant distance to raise its uncertainity above the parameter called LostThresholdDistance to be considered lost. </li>
<li>
LostThresholdDistance: (100 mm) This threshold will only come into play if none of the samples during sensor correction step, score higher than the pass threshold. As soon as this happens, the localization uncertainity distance will grow based on the movement from the last localized pose. If the robot pose computed by the kalman filter has its position uncertainity greater than this distance, the robot will be considered lost as far as localization is concerned. </li>
<li>
PeturbX: (10 mm) After sensor correction and resampling the chosen pose is perturbed to generate a new sample. This parameter decides the range to perturb the X axis in mm. </li>
<li>
PeturbY: (10 mm) Same as above for the Y.. This parameter decides the range to perturb at in the Y axis in mm. </li>
<li>
PeturbTh: (1 deg) Same as above for the Theta. This parameter decides the range to perturb at in the angle in degs. </li>
<li>
FailedX: (300 mm) Range of the box in the X axis in mm to distribute samples after localization fails. </li>
<li>
FailedY: (300 mm) Range of the box in the Y axis in mm to distribute samples after localization fails. </li>
<li>
FailedTh: (45 deg) Range of the angle in degs to distribute samples after localization fails. </li>
<li>
RecoverOnFail: (false) If localization fails, this flag will decide if a static localization is attempted around last known robot pose. Such a reinitialization can cause the robot to be hopelessly lost if the actual robot is very different from its last known pose. </li>
<li>
PeakStdX: (10 mm) If the standard deviation of all the X coords of the samples lie within this number then the localization is considered to have a unique solution. If not, the localization is considered to have multiple solutions. </li>
<li>
PeakStdY: (10 mm) Same as above but pertains to the Y axis in mm. </li>
<li>
PeakStdTh: (1 deg) Same as above but pertains to the Angle in degrees. </li>
<li>
PeakFactor: (0.000001) When a number of distinct samples poses have non zero probabilities such as when there are ambiguities along the center of a long corridor. This is the threshold below the maximum probability to be considered a valid hypothesis. </li>
<li>
StdX: (200 mm) The standard deviation of the Gaussian ellipse when localization is initialized in a map. </li>
<li>
StdY: (200 mm) Same as above but pertains to the Y axis in mm. </li>
<li>
StdTh: (30 deg) Same as above but pertains to the Angle in degrees. </li>
<li>
KMmPerMm: (0.2) When the robot moves linearly, the error in distance is proportional to the distance moved. This error is is given as a fraction in mm per mm. </li>
<li>
KDegPerDeg (0.2) When the robot rotates, the error in the angle is proportional to the angle turned. This is expressed as a fraction in degs per deg. </li>
<li>
KDegPerMm (0.01) When the robot moves linearly it can also affect its orientation. This drift can be expressed as a fraction in degs per mm. </li>
<li>
TriggerDistance: (200 mm) Since MCL localization is computationally expensive, it is triggered only when the robot has moved this far in mm. </li>
<li>
TriggerAngle: (5 deg) Same as above but now it triggers when the robot has turned this far in degs. </li>
<li>
TriggerTime (0msec) Since MCL localization is computationally expensive, it is triggered only when the robot has been idle for this long in milliseconds. (A value of 0 will disable the feature) </li>
<li>
TriggerTimeX (100 mm) When localization is triggered by time this parameter decides the range of the samples in X coords in mm. </li>
<li>
TriggerTimeY (100 mm) When localization is triggered by time this parameter decides the range of the samples in Y coords in mm. </li>
<li>
TriggerTimeTh (180 deg) When localization is triggered by time this parameter decides the range of the samples in Theta coords in degs. </li>
<li>
SensorBelief: (0.9) Probability that a range reading from the laser is valid. This is used in the correction of the probabilities of the samples using the sensor. </li>
<li>
ObsThreshold: (0.1) The threshold value of the occupancy grid to consider as occupied. </li>
<li>
AngleIncrement: (0 deg) The localization will use only one out of every this many degrees in the laser. The lower limit is decided by the LaserIncrement setting. </li>
<li>
DiscardThreshold: (0.33) A robot sample pose lying inside an occupancy grid cell with a value above this will be usually discarded. This is useful in cases where robot may intersect map points such as during patrolbot docking. </li>
<li>
ScoreToVarFactor (4.0) When MCL based localization is combined with other localizations using the variance and mean. The variance of the pose XY in the MCL is increased by the exp(1/pow(score, ScoreToVarFactor) to avoid swamping the other localizations with its typically low values. </li>
<li>
<p class="startli">FuseAllSensors (true) ARNL uses a Kalman filter which allows you to combine the data from the MCL localization, the movement from the encoder between cycles and reflectors if mapped and seen by the laser. This advanced feature can be disabled to revert to the basic MCL localization, using this flag.</p>
<p class="endli"></p>
</li>
<li>
EnableReflectorLocalization (false) This flag will allow the kalman filter to incorporate any reflector measurements along with the odometry to compute the pose of the robot. </li>
<li>
ReflectorVar (100000.0 mm*mm) This number will be used as the variance of the (x, y) coords of the center of the reflectors in the R matrix of the Kalman filter. </li>
<li>
ReflectorMatchDist (2000.0 mm) When matching a seen reflector with a known reflector in the map. This will be the maximum distance to be considered a match. </li>
<li>
ReflectorMatchAngle (5.0 degs) When matching a seen reflector with a known reflector in the map. This will be the maximum angle from the robot to the known and seen reflector points. </li>
<li>
ReflectorMaxRange (8000.0 mm) This is the maximum distance that the SICK lrf is capable of seeing a reflector. (This is smaller than the max range of the regular SICK readings). </li>
<li>
ReflectorMaxAngle (30.0 deg) This is the maximum angle of incidence that the SICK lrf is capable of seeing a reflector at. (This is much smaller than the angle that the regular SICK readings are capable of returning). </li>
<li>
ReflectorSize (300.0 mm) When clustering the reflector points in the laser return, all reflector points inside this range will be classed as belonging to one reflector. </li>
<li>
ReflectorAngleVarLimit (0.0 deg) The (2, 2) element in the kalman filter P for the reflector localization seems to be too small. This may swamp out the angle information from the other localizations. Till a solution is found this is artificial lower limit imposed on the (2, 2) element. </li>
<li>
BadReflectorFactor (1000.0) When reflectors are far away, they are sensed as lone points. Such points sometimes flicker between edges if they are just around a corner. This can mess up localization. So the variance on x and y for this measurement will be increased by this factor in such cases. </li>
<li>
EnableTriangulationFlag (false) When possible the kalman cycle will resort to triangulation when multiple reflectors are seen. This flag can be used to disable this from happening. </li>
<li>
ReflectorTriDistLimit (500.0 mm) When possible the kalman cycle will resort to triangulation when multiple reflectors are seen and triangulation is enabled. The resulting pose will be allowed if the standard deviation in the XY coords is less this limit. </li>
<li>
<p class="startli">ReflectorTriAngLimit (5.0 degs) When possible the kalman cycle will resort to triangulation when multiple reflectors are seen and triangulation is enabled. The resulting pose will be allowed if the standard deviation in the angle coord is less this limit.</p>
<p class="endli"></p>
</li>
<li>
QTra (10000.0 mm*mm) The variance of X and Y coords in the kalman filter's plant model. </li>
<li>
QRot (100.0 deg*deg) The variance of Theta coords in the kalman filter's plant model. </li>
<li>
QTraVel (1.0 (mm/s)^2) The variance of X and Y velocity in the kalman filter's plant model. </li>
<li>
QRotVel (1.0 (deg/s)^2) The variance of rot velocity in the kalman filter's plant model. </li>
<li>
QTraAcc (1.0 (mm/s/s)^2) The variance of X and Y acceleration in the kalman filter's plant model. (not used) </li>
<li>
QTraRot (1.0 (deg/s/s)^2) The variance of rotational acceleration in the kalman filter's plant model. (not used) </li>
<li>
XYLimit (1000.0 mm) Three times this limit will be the maximum innovation allowed in the XY coords during sensor update. If the innovation exceeds this it will be considered an outlier and the sensor reading will be ignored (not used). </li>
<li>
ThLimit (10.0 deg) Three times this limit will be the maximum innovation allowed in the theta coords during sensor update. If the innovation exceeds this it will be considered an outlier and the sensor reading will be ignored (not used). </li>
<li>
UseAllK (true) The gain matrix K of the Kalman is sensitive to the values of Q and R especially about the elements related to the angle. In some cases, it might be easier to blank out all innovations related to the angle from all measurements. This is the flag to use in that case. </li>
<li>
<p class="startli">LogFlag (false) Flag to write kalman debug data into file.</p>
<p class="endli"></p>
</li>
</ol>
</div></div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Wed Nov 15 2017 13:35:45 for ARNL by
    <a href="http://www.doxygen.org/index.html">
    <img class="footer" src="doxygen.png" alt="doxygen"/></a> 1.8.1 </li>
  </ul>
</div>
</body>
</html>
